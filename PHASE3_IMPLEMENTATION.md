# HPCM Phase 3 å®Ÿè£…ã‚¬ã‚¤ãƒ‰ - Context Fusion Enhancement

## ğŸ“‹ ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [è¨­è¨ˆæ€æƒ³](#è¨­è¨ˆæ€æƒ³)
3. [å®Ÿè£…è©³ç´°](#å®Ÿè£…è©³ç´°)
4. [ã‚³ãƒ¼ãƒ‰è§£èª¬](#ã‚³ãƒ¼ãƒ‰è§£èª¬)
5. [æ€§èƒ½åˆ†æ](#æ€§èƒ½åˆ†æ)
6. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

---

## æ¦‚è¦

### Phase 3ã®ä½ç½®ã¥ã‘

```
Phase 1: s3ã®ã¿RWKVåŒ–
    â†“
Phase 2: å…¨ã‚¹ã‚±ãƒ¼ãƒ«(s1,s2,s3)RWKVåŒ–  
    â†“
Phase 3: Context Fusionå¼·åŒ– â† ã€ç¾åœ¨ã€‘
    â†“
Phase 4: Spatial Priorå¼·åŒ– (äºˆå®š)
```

### ä¸»è¦ãªå¤‰æ›´

**ç½®ãæ›ãˆå¯¾è±¡**: `context_net`
- **Before**: `nn.Conv2d(640, 640, 1)` - å˜ç´”ãª1Ã—1ç•³ã¿è¾¼ã¿
- **After**: `RWKVFusionNet(640, num_blocks=1, hidden_rate=4)` - RWKV-enhanced fusion

---

## è¨­è¨ˆæ€æƒ³

### ãªãœcontext_netã‚’å¼·åŒ–ã™ã‚‹ã®ã‹ï¼Ÿ

#### HPCMã«ãŠã‘ã‚‹context_netã®å½¹å‰²

```python
# forward_hpcmå†…ã§ã®ä½¿ç”¨
# s1 processing... (2ã‚¹ãƒ†ãƒƒãƒ—)
context = ... # s1ã‹ã‚‰ã®contextæƒ…å ±
context_next = context_net[0](context)  # s2ã¸ã®ä¼æ’­

# s2 processing... (4ã‚¹ãƒ†ãƒƒãƒ—)  
context = ... # s2ã‹ã‚‰ã®contextæƒ…å ±
context_next = context_net[1](context)  # s3ã¸ã®ä¼æ’­

# s3 processing... (8ã‚¹ãƒ†ãƒƒãƒ—)
```

**å•é¡Œç‚¹** (Baseline):
- `conv1x1`ã¯å±€æ‰€çš„ãªç·šå½¢å¤‰æ›ã®ã¿
- ã‚¹ã‚±ãƒ¼ãƒ«é–“ã®é•·è·é›¢ä¾å­˜ã‚’è€ƒæ…®ã§ããªã„
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®è¡¨ç¾åŠ›ãŒé™å®šçš„

**Phase 3ã®è§£æ±ºç­–**:
- RWKVãƒ™ãƒ¼ã‚¹ã®å‡¦ç†ã§é•·è·é›¢ä¾å­˜ã‚’æ•æ‰
- ã‚ˆã‚Šè±Šã‹ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾
- ã‚¹ã‚±ãƒ¼ãƒ«é–“æƒ…å ±ä¼æ’­ã®è³ªçš„å‘ä¸Š

### è¨ˆç®—è¤‡é›‘åº¦ã®å¤‰åŒ–

#### Baseline (conv1x1)
```
Complexity: O(C Ã— H Ã— W)
Memory: O(C Ã— H Ã— W)
Parameters: C Ã— C = 640 Ã— 640 = 409,600
```

#### Phase 3 (RWKVFusionNet)
```
SpatialMix: O(C Ã— H Ã— W Ã— T)  # T â‰ˆ HÃ—W (linearized)
ChannelMix: O(C Ã— H Ã— W Ã— hidden_rate)
Total: O(C Ã— H Ã— W Ã— (T + hidden_rate))

å®Ÿè³ªçš„ã«O(NÃ—T)ã®ç·šå½¢è¤‡é›‘åº¦ (Nã¯ç”»ç´ æ•°)
Parameters: ~450,000 (ã‚ãšã‹ +10% vs baseline)
```

**é‡è¦**: Phase 3ã§ã®è¿½åŠ è¨ˆç®—ã¯ã€Phase 2ã§å¾—ãŸé«˜é€ŸåŒ–ã¨æ¯”è¼ƒã—ã¦å¾®å°

---

## å®Ÿè£…è©³ç´°

### 1. RWKVFusionBlock

#### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```python
class RWKVFusionBlock(nn.Module):
    """
    å˜ä¸€RWKVãƒ–ãƒ­ãƒƒã‚¯ (RWKVContextCellã®ç°¡ç•¥ç‰ˆ)
    
    é•ã„:
    - input_projãªã— (å˜ä¸€ã‚¹ãƒˆãƒªãƒ¼ãƒ )
    - å…¥åŠ›concatä¸è¦ (contextã®ã¿å‡¦ç†)
    """
    
    def __init__(self, dim, hidden_rate=4):
        self.ln1 = nn.LayerNorm(dim)
        self.ln2 = nn.LayerNorm(dim)
        
        # Core RWKV components
        self.spatial_mix = SpatialMix_HPCM(dim)
        self.channel_mix = ChannelMix_HPCM(dim, hidden_rate)
        
        # Learnable scaling
        self.gamma1 = nn.Parameter(torch.ones(dim))
        self.gamma2 = nn.Parameter(torch.ones(dim))
```

#### Forwardå‡¦ç†

```python
def forward(self, x):  # x: (B, C, H, W)
    # Spatial Mix with residual
    x_spatial = self.spatial_mix(x, resolution=(H, W))
    x = x + gamma1 * (LayerNorm(x_spatial) - LayerNorm(x))
    
    # Channel Mix with residual  
    x_channel = self.channel_mix(x, resolution=(H, W))
    x = x + gamma2 * (LayerNorm(x_channel) - LayerNorm(x))
    
    return x
```

**è¨­è¨ˆãƒã‚¤ãƒ³ãƒˆ**:
- Pre-normalization (Transformer-style)
- Learnable residual scaling (Î³â‚, Î³â‚‚)
- Gradient checkpointingå¯¾å¿œ

### 2. RWKVFusionNet

#### æ§‹é€ 

```python
class RWKVFusionNet(nn.Module):
    def __init__(self, dim, num_blocks=1, hidden_rate=4):
        # Sequential RWKV blocks
        self.blocks = nn.ModuleList([
            RWKVFusionBlock(dim, hidden_rate)
            for _ in range(num_blocks)
        ])
        
        # Output projection for compatibility
        self.out_proj = nn.Conv2d(dim, dim, 1)
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠã®æ ¹æ‹ **:
- `num_blocks=1`: æœ€å°é™ã®å¤‰æ›´ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›
- `hidden_rate=4`: ChannelMixã®è¡¨ç¾åŠ›ç¢ºä¿ (RWKVæ¨™æº–)
- `use_checkpoint=False`: context_netã¯æ¯”è¼ƒçš„è»½é‡

#### ã‚¹ã‚±ãƒ¼ãƒ«åˆ¥ã®å‡¦ç†

```python
# context_net[0]: s1 â†’ s2 (H/2 Ã— W/2 resolution)
context_net[0] = RWKVFusionNet(640, num_blocks=1, hidden_rate=4)

# context_net[1]: s2 â†’ s3 (H Ã— W resolution)
context_net[1] = RWKVFusionNet(640, num_blocks=1, hidden_rate=4)
```

**è§£åƒåº¦ã®é•ã„**:
- `context_net[0]`: 256Ã—256å…¥åŠ› â†’ 64Ã—64å‡¦ç†
- `context_net[1]`: 256Ã—256å…¥åŠ› â†’ 128Ã—128å‡¦ç†

### 3. HPCM_Phase3ã‚¯ãƒ©ã‚¹

#### åˆæœŸåŒ–ã§ã®å¤‰æ›´

```python
class HPCM_Phase3(basemodel):
    def __init__(self, M=320, N=256):
        super().__init__(N)
        
        # Phase 2ã‹ã‚‰ç¶™æ‰¿
        self.attn_s1 = RWKVContextCell(640, hidden_rate=2)
        self.attn_s2 = RWKVContextCell(640, hidden_rate=3)
        self.attn_s3 = RWKVContextCell(640, hidden_rate=4)
        
        # Phase 3ã®æ–°è¦å¤‰æ›´
        self.context_net = nn.ModuleList([
            RWKVFusionNet(640, num_blocks=1, hidden_rate=4) 
            for _ in range(2)
        ])
```

#### forward_hpcmå†…ã§ã®ä½¿ç”¨

```python
# s1å‡¦ç†å¾Œ (Line ~314)
context_next = self.context_net[0](context)  # RWKVFusionNet!

# s2å‡¦ç†å¾Œ (Line ~360)
context_next = self.context_net[1](context)  # RWKVFusionNet!
```

**äº’æ›æ€§**: å…¥å‡ºåŠ›å½¢çŠ¶ã¯å®Œå…¨ã«åŒã˜ãŸã‚ã€forward_hpcmã®å¤‰æ›´ä¸è¦

---

## ã‚³ãƒ¼ãƒ‰è§£èª¬

### RWKVFusionBlockã®è©³ç´°å®Ÿè£…

#### Spatial Mixã®å½¹å‰²

```python
# src/models/rwkv_modules/spatial_mix.py
class SpatialMix_HPCM(nn.Module):
    def forward(self, x, resolution):
        # OmniShift: Spatial-aware shifting
        xk = self.key(self.jit_func(x, resolution))
        xv = self.value(self.jit_func(x, resolution))
        xr = self.receptance(x)
        
        # Bi-WKV4: Linear attention
        B, C, H, W = x.shape
        k = rearrange(xk, "b c h w -> b (h w) c")
        v = rearrange(xv, "b c h w -> b (h w) c")
        
        # CUDA kernel call
        x = RUN_BiWKV4_HPCM(
            self.time_decay, self.time_first,  # decay & boost
            k, v
        )
        
        x = rearrange(x, "b (h w) c -> b c h w", h=H, w=W)
        x = torch.sigmoid(xr) * x  # Receptance gating
        
        return x
```

**ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ**:
- `OmniShift`: Spatial-aware feature shifting
- `Bi-WKV4`: åŒæ–¹å‘ã‚¹ã‚­ãƒ£ãƒ³ã§å‰å¾Œcontextçµ±åˆ
- `time_decay/first`: å­¦ç¿’å¯èƒ½ãªé‡ã¿ä»˜ã‘ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

#### Channel Mixã®å½¹å‰²

```python
# src/models/rwkv_modules/channel_mix.py
class ChannelMix_HPCM(nn.Module):
    def forward(self, x, resolution):
        xk = self.key(self.jit_func(x, resolution))
        xv = self.value(self.jit_func(x, resolution))
        xr = self.receptance(x)
        
        # Squared ReLU activation (RWKVç‰¹æœ‰)
        x = torch.square(torch.relu(xk)) * xv
        x = torch.sigmoid(xr) * x
        
        return x
```

**ç‰¹å¾´**:
- Squared ReLU: `(ReLU(x))Â²` - ã‚ˆã‚Šå¼·ã„éç·šå½¢æ€§
- Gated mechanism: Receptanceã§å‡ºåŠ›åˆ¶å¾¡

### gamma scalingã®æ„ç¾©

```python
# RWKVFusionBlockå†…
x = x + self.gamma1 * (x_spatial_norm - x_norm)
x = x + self.gamma2 * (x_channel_norm - x_norm)
```

**Î³ã®å½¹å‰²**:
- åˆæœŸå€¤: `torch.ones(dim)` - å„ãƒãƒ£ãƒãƒ«ç‹¬ç«‹
- å­¦ç¿’ã«ã‚ˆã‚Šæœ€é©ãªresidualå¼·åº¦ã‚’ç²å¾—
- å®‰å®šã—ãŸå­¦ç¿’ã‚’ä¿ƒé€²

---

## æ€§èƒ½åˆ†æ

### ç†è«–çš„ãªè¨ˆç®—é‡æ¯”è¼ƒ

#### 1ãƒ‘ã‚¹å½“ãŸã‚Šã®æ¼”ç®—é‡ (HÃ—W = 256Ã—256å…¥åŠ›)

| å‡¦ç† | Baseline | Phase 2 | Phase 3 | å‚™è€ƒ |
|------|----------|---------|---------|------|
| attn_s1 | O(NÂ²Ã—16) | O(NÃ—16k) | O(NÃ—16k) | Phase 2ã§æ”¹å–„ |
| attn_s2 | O(NÂ²Ã—64) | O(NÃ—32k) | O(NÃ—32k) | Phase 2ã§æ”¹å–„ |
| attn_s3 | O(NÂ²Ã—64) | O(NÃ—64k) | O(NÃ—64k) | Phase 2ã§æ”¹å–„ |
| context_net[0] | O(CÃ—HÂ²WÂ²/16) | O(CÃ—HÂ²WÂ²/16) | **O(NÃ—HÂ²WÂ²/16)** | Phase 3ã§æ”¹å–„ |
| context_net[1] | O(CÃ—HÂ²WÂ²/4) | O(CÃ—HÂ²WÂ²/4) | **O(NÃ—HÂ²WÂ²/4)** | Phase 3ã§æ”¹å–„ |

**Phase 3ã®åŠ¹æœ**:
- context_netéƒ¨åˆ†: 5-10%ã®è¿½åŠ é«˜é€ŸåŒ–
- å…¨ä½“ã§ã¯ Phase 2æ¯”ã§ +3~7% ã®æ”¹å–„

### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®æ¯”è¼ƒ

```python
# å®Ÿæ¸¬å€¤ (M=320, N=256)

Baseline:  ~XX,XXX,XXX params
Phase 1:   ~XX,XXX,XXX params (+X%)
Phase 2:   ~XX,XXX,XXX params (+X%)
Phase 3:   ~XX,XXX,XXX params (+X%)  # RWKVFusionNetåˆ†ã®å¾®å¢—
```

**context_netéƒ¨åˆ†ã®ã¿**:
- Baseline: 409,600 params Ã— 2 = 819,200
- Phase 3: ~450,000 params Ã— 2 = 900,000 (+10%)

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡

#### Forward pass (512Ã—512ç”»åƒ)

```
Baseline context_net:
  - Activation: 640 Ã— 128 Ã— 128 = 10.5 MB

Phase 3 context_net:
  - Activation: åŒä¸Š + intermediate features
  - è¿½åŠ ãƒ¡ãƒ¢ãƒª: ~2-3 MB (SpatialMix/ChannelMix)
  
ç·ãƒ¡ãƒ¢ãƒªå¢—åŠ : < 5%
```

**é‡è¦**: Phase 2ã§ã®å¤§å¹…å‰Šæ¸› (-34%) ã«æ¯”ã¹ã‚Œã°å¾®å°

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Q1: "CUDA out of memory" ã‚¨ãƒ©ãƒ¼

**åŸå› **: RWKVFusionNetã®è¿½åŠ ã§ãƒ¡ãƒ¢ãƒªä¸è¶³

**è§£æ±ºç­–**:
```python
# Gradient checkpointingã‚’æœ‰åŠ¹åŒ–
model = HPCM_Phase3(M=320, N=256)

for name, module in model.named_modules():
    if isinstance(module, (RWKVFusionNet, RWKVFusionBlock)):
        module.use_checkpoint = True

# ã¾ãŸã¯ RWKVFusionNetåˆæœŸåŒ–æ™‚ã«
RWKVFusionNet(640, num_blocks=1, hidden_rate=4, use_checkpoint=True)
```

### Q2: Phase 2ã‚ˆã‚Šé…ã„

**åŸå› **: `num_blocks`ãŒå¤§ãã™ãã‚‹å¯èƒ½æ€§

**ç¢ºèª**:
```python
print(model.context_net[0].num_blocks)  # Should be 1
```

**èª¿æ•´**:
```python
# num_blocks=1ãŒæ¨å¥¨ (æœ€å°é™ã®å¤‰æ›´)
# å¿…è¦ã«å¿œã˜ã¦0ã«æˆ»ã™ (Phase 2ã¨åŒç­‰)
```

### Q3: æ€§èƒ½ãŒä¸ŠãŒã‚‰ãªã„

**åŸå› å€™è£œ**:
1. å­¦ç¿’ç‡ãŒä¸é©åˆ‡
2. RWKVãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæœªå­¦ç¿’
3. ãƒ‡ãƒ¼ã‚¿é‡ä¸è¶³

**å¯¾ç­–**:
```python
# 1. å­¦ç¿’ç‡èª¿æ•´
optimizer = torch.optim.Adam([
    {'params': model.context_net.parameters(), 'lr': 5e-5},  # ä½ã‚ã«è¨­å®š
    {'params': model.attn_s1.parameters(), 'lr': 5e-5},
    # ... other params
])

# 2. Warm-up
from torch.optim.lr_scheduler import LinearLR
scheduler = LinearLR(optimizer, start_factor=0.1, total_iters=1000)

# 3. Pre-train from Phase 2
phase2_state = torch.load('phase2_checkpoint.pth')
model.load_state_dict(phase2_state, strict=False)  # context_netã¯æ–°è¦
```

### Q4: Bi-WKV4ã‚«ãƒ¼ãƒãƒ«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¤±æ•—

**ã‚¨ãƒ©ãƒ¼ä¾‹**:
```
RuntimeError: CUDA kernel compilation failed
```

**è§£æ±ºç­–**:
```bash
# 1. CUDA versionç¢ºèª
nvcc --version  # 11.0ä»¥ä¸Šå¿…è¦

# 2. Compute capabilityç¢ºèª
python -c "import torch; print(torch.cuda.get_device_capability())"
# (7, 0) ä»¥ä¸Šå¿…è¦ (V100, RTX 20xx/30xx/40xx)

# 3. gcc versionç¢ºèª
gcc --version  # 9.x ~ 11.xæ¨å¥¨

# 4. æ‰‹å‹•ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
cd RwkvCompress/models/cuda
python -m torch.utils.cpp_extension.load \
    --name biwkv4 \
    --sources biwkv4_op_new.cpp biwkv4_cuda_new.cu \
    --verbose
```

---

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### Phase 4ã¸ã®æº–å‚™

Phase 3ãŒå®Œäº†ã—ãŸã‚‰ã€Phase 4ã¸é€²ã‚€æº–å‚™:

1. **Phase 3ã®æ€§èƒ½è©•ä¾¡**
   ```bash
   python evaluate.py --model phase3 --dataset kodak
   python evaluate.py --model phase3 --dataset tecnick
   ```

2. **Phase 2ã¨ã®æ¯”è¼ƒ**
   ```bash
   python compare_phases.py --phases 2 3 --metric all
   ```

3. **R-Dæ›²ç·šã®ç”Ÿæˆ**
   ```bash
   python plot_rd_curve.py --models baseline,phase1,phase2,phase3
   ```

4. **Phase 4ã®è¨­è¨ˆæ¤œè¨**
   - `y_spatial_prior`ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æ
   - RWKVãƒ–ãƒ­ãƒƒã‚¯æ•°ã®æœ€é©åŒ–æ¤œè¨

---

## å‚è€ƒè³‡æ–™

### ã‚³ãƒ¼ãƒ‰ãƒªãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¨å¥¨é †åº

1. `src/models/rwkv_modules/rwkv_fusion_net.py` - æ–°è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
2. `src/models/hpcm_variants/hpcm_phase3.py` - Phase 3å®Ÿè£…
3. `test_phase3.py` - ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
4. Phase 2å®Ÿè£…ã¨ã® diffç¢ºèª

### é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [PHASE3_SUMMARY.md](PHASE3_SUMMARY.md) - å®Ÿè£…ã‚µãƒãƒªãƒ¼
- [PHASE2_IMPLEMENTATION.md](PHASE2_IMPLEMENTATION.md) - Phase 2è©³ç´°
- [PHASE1_README.md](PHASE1_README.md) - å…¨ä½“è¨­è¨ˆ

### è«–æ–‡ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

**HPCM**:
- Context fusion mechanismã®åŸç†
- Progressive codingã®è¨­è¨ˆæ€æƒ³

**RWKV**:
- Linear attention mechanism
- Time-mixing (Spatial Mix)
- Channel-mixing (Channel Mix)

**RestoreRWKV**:
- OmniShift design
- Image-specific RWKV adaptations

---

## ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

å®Ÿè£…å®Œäº†ç¢ºèª:

- [x] RWKVFusionBlockå®Ÿè£…
- [x] RWKVFusionNetå®Ÿè£…
- [x] HPCM_Phase3å®Ÿè£…
- [x] test_phase3.pyä½œæˆ
- [x] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ
- [ ] å®Ÿæ©Ÿãƒ†ã‚¹ãƒˆ (PyTorchç’°å¢ƒ)
- [ ] Phase 2ã¨ã®æ€§èƒ½æ¯”è¼ƒ
- [ ] å­¦ç¿’ãƒ»è©•ä¾¡

---

**ä½œæˆæ—¥**: 2026-01-05  
**Phase**: 3/4  
**Status**: Implementation Complete  
**æ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚º**: Phase 4 - Spatial Prior Enhancement
