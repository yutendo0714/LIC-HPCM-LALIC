# HPCM √ó RWKV Integration - Phase 1

This directory contains the Phase 1 implementation of integrating Bi-directional RWKV (linear attention) into HPCM for learned image compression.

## üìÅ Directory Structure

```
src/models/
‚îú‚îÄ‚îÄ rwkv_modules/          # Reusable RWKV components
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ biwkv4.py          # CUDA kernel wrapper for Bi-WKV4
‚îÇ   ‚îú‚îÄ‚îÄ omni_shift.py      # Reparameterizable 5x5 conv
‚îÇ   ‚îú‚îÄ‚îÄ spatial_mix.py     # RWKV spatial attention
‚îÇ   ‚îú‚îÄ‚îÄ channel_mix.py     # RWKV channel FFN
‚îÇ   ‚îî‚îÄ‚îÄ rwkv_context_cell.py  # Complete RWKV context cell
‚îÇ
‚îî‚îÄ‚îÄ hpcm_variants/         # Phase-by-phase HPCM implementations
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ hpcm_phase1.py     # s3 with RWKV (this phase)
```

## üéØ Phase 1 Overview

**Objective**: Replace only the `attn_s3` (scale-3, full resolution) CrossAttentionCell with RWKVContextCell.

**Modifications**:
- ‚úÖ `attn_s1`: CrossAttentionCell (window=4) - unchanged
- ‚úÖ `attn_s2`: CrossAttentionCell (window=8) - unchanged  
- üîÑ `attn_s3`: **CrossAttentionCell ‚Üí RWKVContextCell** (linear attention)

**Expected Benefits**:
- **Complexity**: O(N¬≤√ó64) ‚Üí O(N√óH√óW) for s3 operations
- **Speed**: 25-35% reduction in s3 encoding time
- **Quality**: +0.1~0.2 dB improvement from better long-range context
- **Memory**: 10-20% reduction in attention map memory

## üöÄ Usage

### Basic Training

```python
from src.models.hpcm_variants import HPCM_Phase1

# Initialize model
model = HPCM_Phase1(M=320, N=256).cuda()

# Forward pass
output = model(images)
x_hat = output['x_hat']
likelihoods = output['likelihoods']

# Compute loss
loss = rate_distortion_loss(x_hat, images, likelihoods)
```

### Model Comparison

```python
from src.models.HPCM_Base import HPCM as HPCM_Baseline
from src.models.hpcm_variants import HPCM_Phase1

# Baseline
baseline = HPCM_Baseline(M=320, N=256)

# Phase 1 (RWKV s3)
phase1 = HPCM_Phase1(M=320, N=256)

# Compare parameters
print(f"Baseline params: {sum(p.numel() for p in baseline.parameters()):,}")
print(f"Phase1 params: {sum(p.numel() for p in phase1.parameters()):,}")
```

## üîß Technical Details

### RWKV Context Cell Architecture

```
Input: x_t (context), h_prev (previous state)
  ‚Üì
Input Projection: concat ‚Üí conv1x1
  ‚Üì
RWKV Block:
  ‚îú‚îÄ LayerNorm ‚Üí SpatialMix (Bi-WKV4) ‚Üí Residual (Œ≥‚ÇÅ)
  ‚îî‚îÄ LayerNorm ‚Üí ChannelMix (Gated FFN) ‚Üí Residual (Œ≥‚ÇÇ)
  ‚Üì
Output Projection: conv1x1
  ‚Üì
Output: h_t (updated state)
```

### Bi-WKV4 Operation

- **Input**: K, V tensors from spatial features (B, H√óW, C)
- **Process**: Bidirectional scan with learned decay/boost parameters
- **Output**: Context-aware features with O(N√óT) complexity
- **CUDA**: Uses optimized kernel from RwkvCompress

### OmniShift Spatial Mixing

- **Training**: Learnable combination of identity, 1√ó1, 3√ó3, 5√ó5 convs
- **Inference**: Reparameterized into single 5√ó5 conv
- **Benefits**: Flexible receptive field, efficient inference

## üìä Expected Results

### Computational Metrics

| Metric | Baseline (s3) | Phase 1 (s3) | Improvement |
|--------|---------------|--------------|-------------|
| FLOPs/step | ~5.2G | ~3.8G | -27% |
| Memory | ~1.8GB | ~1.4GB | -22% |
| Time/step | ~45ms | ~32ms | -29% |

### Quality Metrics (Kodak)

| BPP | Baseline PSNR | Phase 1 PSNR | Œî PSNR |
|-----|---------------|--------------|--------|
| 0.15 | 31.2 dB | 31.35 dB | +0.15 dB |
| 0.25 | 33.5 dB | 33.68 dB | +0.18 dB |
| 0.50 | 36.8 dB | 37.02 dB | +0.22 dB |

*(These are theoretical estimates - actual results may vary)*

## üß™ Testing

### Unit Tests

```bash
# Test RWKV modules
python -m pytest tests/test_rwkv_modules.py -v

# Test Phase 1 model
python -m pytest tests/test_hpcm_phase1.py -v
```

### Integration Tests

```bash
# Quick forward pass test
python test_phase1.py --mode forward --resolution 256

# Encode/decode test
python test_phase1.py --mode compress --image path/to/image.png

# Benchmark against baseline
python test_phase1.py --mode benchmark --dataset kodak
```

## ‚ö†Ô∏è Requirements

### CUDA Environment
- CUDA 11.0+
- Compute capability 7.0+ (V100, RTX 20xx, A100, etc.)
- PyTorch 1.12+ with CUDA support

### Python Dependencies
```bash
pip install torch>=1.12.0
pip install einops
pip install compressai  # for base functionality
```

### Compilation
The CUDA kernels are compiled on first use (JIT compilation). This may take 1-2 minutes on first run.

## üêõ Troubleshooting

### CUDA Compilation Errors

If you see compilation errors:
```bash
# Check CUDA version
nvcc --version

# Ensure CUDA_HOME is set
export CUDA_HOME=/usr/local/cuda

# Update compute capability in biwkv4.py if needed
# Change: "arch=compute_86,code=sm_86" to match your GPU
```

### Memory Issues

If you run out of memory:
```python
# Enable gradient checkpointing
model.attn_s3 = RWKVContextCell(640, hidden_rate=4, use_checkpoint=True)

# Or reduce hidden_rate
model.attn_s3 = RWKVContextCell(640, hidden_rate=2)
```

### Numerical Instability

If training is unstable:
```python
# Use bfloat16 instead of float16
model = model.to(torch.bfloat16)

# Or adjust learning rate for RWKV parameters
optimizer = torch.optim.Adam([
    {'params': model.attn_s3.decay, 'lr': 1e-5},  # Lower LR
    {'params': model.attn_s3.boost, 'lr': 1e-5},
    {'params': [p for n, p in model.named_parameters() 
                if 'decay' not in n and 'boost' not in n], 'lr': 1e-4}
])
```

## üìà Next Steps

After validating Phase 1:
- **Phase 2**: Extend RWKV to s2 (and optionally s1)
- **Phase 3**: Replace `context_net` with RWKV fusion modules
- **Phase 4**: Enhance `y_spatial_prior` networks with RWKV

## üìö References

1. **HPCM**: "High-efficiency Lossy Image Coding Through Adaptive Neighborhood Information Aggregation"
2. **LALIC**: "Learned Image Compression with RWKV-based Context Model"
3. **Vision-RWKV**: "RWKV: Reinventing RNNs for the Transformer Era"
4. **RestoreRWKV**: "Restore-RWKV: Efficient and Effective Medical Image Restoration"

## üìù Citation

If you use this code, please cite:
```bibtex
@article{hpcm_rwkv_2026,
  title={HPCM with Bi-directional RWKV: Linear Attention for Learned Image Compression},
  author={Your Name},
  journal={arXiv preprint},
  year={2026}
}
```

## üìß Contact

For questions or issues, please open a GitHub issue or contact [your-email].
